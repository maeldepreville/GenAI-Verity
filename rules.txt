Project: AI Compliance Assistant for
Policy & Regulation Checking - Verity
Context & Motivation
In today’s regulatory landscape, organizations are under immense pressure to ensure their
internal policies—ranging from IT security to HR data management—align with rigorous
external standards like ISO 27001 or GDPR. Currently, this compliance checking process is
largely manual, slow, and prone to human error, as it requires experts to meticulously
interpret complex regulatory language and cross-reference it with internal documentation.
However, recent advancements in Generative AI and Large Language Model (LLM)
reasoning have opened the door to automation. This project capitalizes on these
breakthroughs to build a reliable, interactive, and explainable AI tool capable of acting as a
first-line decision support system for compliance auditing.
Project Objective
The primary goal is to develop an interactive Streamlit application featuring an intelligent
Compliance Agent. This agent is designed to bridge the gap between static documents and
dynamic regulatory requirements.
Unlike a simple keyword search, this tool analyzes user-uploaded policies (PDF or text) and
intelligently compares them against a curated knowledge base of regulations. It identifies
areas of conformity, partial conformity, or non-compliance, and generates a scored report
with specific corrective recommendations. Crucially, the system focuses on
"explainability"—showing the user the step-by-step reasoning behind every conclusion.
Note: This assistant acts as a technical decision-support tool to aid auditors and
managers, not as a replacement for legal counsel.
Core Functionality & Workflow
The application follows a streamlined workflow designed for ease of use and technical
robustness:
1. Input & Ingestion The workflow begins when a user uploads a policy document and
selects a specific regulatory framework (e.g., ISO 27001 controls or GDPR principles).
2. Document Understanding & RAG Once uploaded, the system performs text extraction
and segmentation. It utilizes Retrieval-Augmented Generation (RAG) to fetch the specific
controls relevant to the policy from a local vector database. By using embedding-based
similarity search, the system ensures that the LLM is analyzing the policy against the correct
specific rules, rather than general knowledge.
3. Analysis & Reporting For each regulatory requirement identified, the agent compares
the policy text to the rule. It generates a detailed analysis that includes:
● A classification (Compliant, Partial, or Not Compliant).
● A citation of the specific policy sections that matched the rule.
● A global compliance score and risk overview.
● Actionable recommendations for fixing non-compliant sections.
Advanced Reasoning Techniques
To ensure the output is high-quality and hallucinates as little as possible, the "brain" of the
agent relies on several advanced prompting strategies:
● Chain of Thought (CoT): We implement step-by-step reasoning prompts, forcing the
model to logically deconstruct the policy before assigning a score.
● ReAct (Reasoning + Acting): The model follows a loop of Thought → Tool
(Retrieval) → Observation → Analysis, allowing it to dynamic query the regulation
database.
● Self-Correction: The system performs a "second pass" review of its own output to
refine consistency and catch logical errors before showing the result to the user.
● Tree of Thoughts (Optional): Utilized for ambiguous cases where multiple
interpretations of a rule might apply.
Expected Deliverables
● Streamlit Application: A fully functional web interface.
● GitHub Repository: Clean, structured code with a comprehensive README
detailing the reasoning techniques used.
● Video Demo: A walkthrough of the application analyzing a real-world document.
● Project Summary: A one-page abstract (this document).
Impact & Relevance
This project moves beyond theoretical AI to demonstrate how Large Language Models can
solve critical business challenges in audit, risk management, and compliance automation.
For the engineering team, it serves as a showcase of applied skills in LLM reasoning, RAG
system architecture, and document processing. It highlights the ability to build real-world
AI interfaces that solve complex, unstructured data problems—skills highly sought after in
roles like AI Engineering and ML SaaS development